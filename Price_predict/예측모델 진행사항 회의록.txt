27.456882

0.963643

다중공선성이 있는 경우
Ridge / Lasso / Elastic net regression
다중공선성이 있는 데이터에 대해서 그냥 고전적인 선형 회귀 모델을 
만들게 되면 회귀 계수의 영향력이 과다 추정될 수 있습니다. 

이런 문제를 피하기 위해 가장 널리 알려진 방법이 ‘regularization’이라고 부르는
 기법입니다. 여기서 소개하는 Ridge / lasso / elastic net 이 모두 이런 regularization
 을 이용한 회귀 모델링 기법입니다. 이것 역시 로버스트 회귀처럼 모델의 형태 자체는
 고전적인 선형 회귀 모델과 동일하나 회귀 계수를 추정하는 방식에서 차이가 있습니다
. 말로 설명하기에 앞서 우선 수식으로 표현하면 아래와 같습니다.
위 수식을 보면 고전적인 선형 회귀 모델은 회귀 계수를 추정할 때 잔차의 제곱의 합을 
계산합니다. 이 함수를 비용함수라고 부르는데 이 비용 함수가 최소가 되는 회귀 계수를
 찾는 것이죠. 그런데 여기서 소개하는 회귀 모델들은 이 비용함수에
 (그림에서 빨간색으로 표시한) 추가적인 수식들이 붙습니다.
 이런 추가적인 수식을 페널티 함수라고 부릅니다. 말그대로 회귀 계수 값 자체가
 너무 커지지 않도록 페널티를 줌으로써 회귀계수값들이 과다 추정되는 것을 막는 것입니다. 이 때 페널티 함수의 형태에 따라 ridge 와 lasso 가 구분됩니다. ridge regression 은 회귀 계수의 제곱합을 계산하는 방식이고, lasso 는 회귀 계수의 절대값을 계산하는 방식입니다. 그리도 elastic net은 이 둘을 결합한 방식이죠.

이런 페널티 함수를 이용하면 다중공선성이 있더라도 회귀 계수 과다 추정을 막을 수
 있으며, 더 나아가 모델이 overfitting 되는 문제도 어느 정도 완화시킬 수 있습니다.
 그래서 보통 독립 변수의 개수가 데이터의 개수에 비해 너무 많은 경우에 이 기법을
 사용합니다. 특히 lasso regression은 영향력이 적은 변수의 회귀 계수값을 0으로
 만들기 때문에 일종의 변수 선택 효과까지 있는 장점이 있습니다.

참고한 사이트
회귀모델의 종류 ridge lasso를 사용하는 이유
https://danbi-ncsoft.github.io/study/2018/05/04/study-regression_model_summary.html

머신러닝 -> 딥러닝 
LSTM  :  -> 딥러닝 모델로 돌려보기 

편의시설 컬럼을 추가하고 동을 대체 해보고 
라벨 인코딩을 안하고 각각의 (동별로) 링크에 대해서 따로 학습 
-> 



2022/10/08

머신러닝팀 할일
1.  우리가 할일 편의시설로 동을 대체한 후 송파구에서 성능 향상되는지 확인 
   -> 전체 데이터에 구별로 한거 -> 라벨인코딩 후 구별로 안나누고 데이터 다써서 학습
   결과 비교

2. 머신러닝을 다써봄 -> 딥러닝으로 돌려보고 성능 비교하기 

3. 모델을 동별로 만들어서 성능 비교해보기 -> 라벨 인코딩 안하기

4. 추가적으로 도메인 및 통계적 지식을 바탕으로 문서에 내용 추가 